{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset head:\n",
      "      v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "\n",
      "Columns:\n",
      " Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n",
      "\n",
      "Data types:\n",
      " v1            object\n",
      "v2            object\n",
      "Unnamed: 2    object\n",
      "Unnamed: 3    object\n",
      "Unnamed: 4    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "data = pd.read_csv('textspamdata.csv', encoding='latin-1')  # Ensure the file is in the same directory or provide full path\n",
    "\n",
    "# Inspecting the first few rows of the dataset to verify its structure\n",
    "print(\"Dataset head:\\n\", data.head())\n",
    "print(\"\\nColumns:\\n\", data.columns)\n",
    "print(\"\\nData types:\\n\", data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset head:\n",
      "   label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "Columns after renaming:\n",
      " Index(['label', 'message'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "data = data[['v1', 'v2']]\n",
    "\n",
    "# Renaming columns: 'v1' to 'label' and 'v2' to 'message'\n",
    "data = data.rename(columns={'v1': 'label', 'v2': 'message'})\n",
    "\n",
    "# Verifying the changes\n",
    "print(\"Cleaned dataset head:\\n\", data.head())\n",
    "print(\"\\nColumns after renaming:\\n\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preprocessed training messages:\n",
      " 1978    no i m in the same boat still here at my moms ...\n",
      "3989    bank of granite issues strong buy explosive pi...\n",
      "3935        they r giving a second chance to rahul dengra\n",
      "4078              o i played smash bros lt gt religiously\n",
      "4086    private your 2003 account statement for 079737...\n",
      "Name: message, dtype: object\n",
      "\n",
      "Labels:\n",
      " 1978    0\n",
      "3989    1\n",
      "3935    0\n",
      "4078    0\n",
      "4086    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n",
    "# Encoding the labels: 'ham' as 0 and 'spam' as 1\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Preprocessing the text: Convert to lowercase and remove unwanted characters\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "data['message'] = data['message'].apply(preprocess_text)\n",
    "\n",
    "# Splitting the data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the first few rows of the processed training data\n",
    "print(\"Sample preprocessed training messages:\\n\", X_train.head())\n",
    "print(\"\\nLabels:\\n\", y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data vectors: (4457, 3000)\n",
      "Shape of test data vectors: (1115, 3000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initializing the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=3000)  # Limiting to 3000 features to reduce dimensionality\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Displaying the shape of the resulting vectors to confirm transformation\n",
    "print(\"Shape of training data vectors:\", X_train_vec.shape)\n",
    "print(\"Shape of test data vectors:\", X_test_vec.shape)\n",
    "\n",
    "# Saving the vectorizer for later use\n",
    "import joblib\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.968609865470852\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       965\n",
      "           1       0.99      0.77      0.87       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[964   1]\n",
      " [ 34 116]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['phishing_text_classifier.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initializing the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)  # Increase max_iter if convergence issues arise\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Logistic Regression model:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Saving the trained model for later use\n",
    "joblib.dump(model, \"phishing_text_classifier.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraudenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
